{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<p><img src=\"https://mcd.unison.mx/wp-content/themes/awaken/img/logo_mcd.png\" width=\"150\">\n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "<h1>Curso Procesamiento de Lenguaje Natural</h1>\n",
    "\n",
    "<h3>LSTM básico: Haciendo N-gramas</h3>\n",
    "\n",
    "\n",
    "<p> Julio Waissman Vilanova </p>\n",
    "<p>\n",
    "<img src=\"https://identidadbuho.unison.mx/wp-content/uploads/2019/06/letragrama-cmyk-72.jpg\" width=\"150\">\n",
    "</p>\n",
    "\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/mcd-unison/pln/blob/main/labs/RNN/deep-ngram.ipynb\"><img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\"  width=\"30\" /> Ejecuta en Colab</a>\n",
    "\n",
    "Tomado parcialmente y adaptado de [el repositorio de github](https://github.com/shaundsouza/lstm-textual-ngrams) del trabajo [*LSTM Neural Network for Textual Ngrams* (D'Souza, 2018)](https://www.preprints.org/manuscript/201811.0579/v1)\n",
    "\n",
    "\n",
    "\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando datos de alguna obra \n",
    "\n",
    "Vamos a descargar un *Corpus*, y pues vamos a usar algo muy famoso, como  puede ser la obra de Shakespiare en inglés, o *El Quijote* en español. Empecemos por *El Quijote*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -o quijote.txt https://www.gutenberg.org/cache/epub/2000/pg2000.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y ahora si vamos a ver como nos quedaría el texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = \"quijote.txt\"\n",
    "with open(archivo, 'r', encoding='utf8') as fp:\n",
    "    corpus = fp.read()\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesando la información para ser utilizada en un modelo tipo LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a generar dos íncides, de indices a caracteres y de caracteres a ´ndices. Y sin dar ni media pasada de limpieza. Ya veremos si limpiamos el texto como queda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(corpus)))\n",
    "char_indices = {c: i for i, c in enumerate(chars)}\n",
    "indices_char = {i: c for i, c in enumerate(chars)}\n",
    "\n",
    "print('# de caracteres:', len(chars))\n",
    "print(char_indices.keys())\n",
    "for i in range(20):\n",
    "  print(f\"indices_char[{i}] = {indices_char[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora vamos a dividir entre entradas y salidas, donde cada entrada es una cadena de maxlen caracteres, la salida es el próximo caracter, y vamos avanzando en el texto en saltos (`step`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(corpus) - maxlen, step):\n",
    "    sentences.append(corpus[i: i + maxlen])\n",
    "    next_chars.append(corpus[i + maxlen])\n",
    "\n",
    "print(sentences[:10])\n",
    "print(next_chars[:10])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora vamos a convertirlos a tensores, usando la codificación de `one hot encoding`, que es la más malita posible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "# build the model: a single LSTM\n",
    "print(\"x \", x.shape)\n",
    "print(\"y \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado neuronal\n",
    "\n",
    "Definamos un modelo bastante simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = keras.Sequential([\n",
    "  layers.LSTM(128, input_shape=(maxlen, len(chars))),\n",
    "  layers.Dense(len(chars), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y lo entrenamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones\n",
    "\n",
    "En este caso, lo que queremos es que el sistema realice una predicción simple, usando los valores pasados para predecir el nuevo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def predict_text(modelo, inicial, caracteres=10, char_indices, indices_char temperature=1.0):\n",
    "  generado = inicial\n",
    "  for i in range(caracteres):\n",
    "    x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "\n",
    "    for t, char in enumerate(sentence):\n",
    "      x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "    preds = modelo.predict(x_pred)[0]\n",
    "    next_index = sample(preds, temperature)\n",
    "    next_char = indices_char[next_index]\n",
    "\n",
    "    generado += [next_char]\n",
    "  return generado\n",
    "          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1\n",
    "inicial = \"De verdad os digo que\"\n",
    "\n",
    "a = predict_text(\n",
    "    modelo, \n",
    "    inicial, \n",
    "    caracteres=20, \n",
    "    char_indices, \n",
    "    indices_char,\n",
    "    temperature=T)\n",
    "\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
