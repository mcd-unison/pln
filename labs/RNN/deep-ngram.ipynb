{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<p><img src=\"https://mcd.unison.mx/wp-content/themes/awaken/img/logo_mcd.png\" width=\"150\">\n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "<h1>Curso Procesamiento de Lenguaje Natural</h1>\n",
    "\n",
    "<h3>LSTM básico: Haciendo N-gramas</h3>\n",
    "\n",
    "\n",
    "<p> Julio Waissman Vilanova </p>\n",
    "<p>\n",
    "<img src=\"https://identidadbuho.unison.mx/wp-content/uploads/2019/06/letragrama-cmyk-72.jpg\" width=\"150\">\n",
    "</p>\n",
    "\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/mcd-unison/pln/blob/main/labs/RNN/deep-ngram.ipynb\"><img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\"  width=\"30\" /> Ejecuta en Colab</a>\n",
    "\n",
    "Tomado parcialmente y adaptado de [el repositorio de github](https://github.com/shaundsouza/lstm-textual-ngrams) del trabajo [*LSTM Neural Network for Textual Ngrams* (D'Souza, 2018)](https://www.preprints.org/manuscript/201811.0579/v1)\n",
    "\n",
    "\n",
    "\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando datos de alguna obra \n",
    "\n",
    "Vamos a descargar un *Corpus*, y pues vamos a usar algo muy famoso, como  puede ser la obra de Shakespiare en inglés, o *El Quijote* en español. Empecemos por *El Quijote*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -o quijote.txt https://www.gutenberg.org/cache/epub/2000/pg2000.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y ahora vamos a descargar el corpus por lineas de texto, eliminando cabecera y final de Gutemberg, quitando espacios, moviendo todas las letras a minúsculas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = \"quijote.txt\"\n",
    "corpus = []\n",
    "with open(archivo, 'r', encoding='utf8') as fp:\n",
    "    guarda = False\n",
    "    for line in fp.readlines():\n",
    "      if \"*** END OF THE PROJECT GUTENBERG\" in line:\n",
    "        break\n",
    "      if guarda and len(line) > 2:\n",
    "        corpus.append(line.strip())\n",
    "      if \"*** START OF THE PROJECT GUTENBERG\" in line:\n",
    "        guarda = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos como de ve el corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Inicio del texto: \\n{corpus[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Fin del texto: \\n{corpus[-10:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(corpus))\n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesando la información \n",
    "\n",
    "Para el preprocesamiento, vamos a convertir a tokens cada linea de texto y vamos a agregar pads al mas largo de los textos que se encuentran en el documento (antes de cada salto de linea). Vamos a utilizar la capa de `TextVectorization` que ofrece `Keras`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 10_000\n",
    "\n",
    "indizador = layers.TextVectorization(max_tokens=max_tokens)\n",
    "indizador.adapt(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo que tenemos un nuevo vocabulario que podemos ver en orden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = indizador.get_vocabulary()\n",
    "print(f\"Tenemos un vocabulario de {len(vocab)} tokens\")\n",
    "print(f\"Y aquí están las primeras 20 palabras:\\n{vocab[:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora vamos a convertir el *corpus* en tensores de tokens simplemente como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entradas = indizador(corpus)\n",
    "\n",
    "print(f\"Las entradas en un tensor con un shape de:\\n{entradas.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver tenemos una serie de tokens por linea (o muestra) que se generó del *corpus*. Ahora vamos poniendo la secuencia de salida. \n",
    "\n",
    "Como lo que queremos es estimar la próxima palabra, pues no queda mas que usar los mismos tokens de entrada, pero con un corrimiento hacia la izquierda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salidas = tf.roll(entradas, shift=-1, axis=1)\n",
    "\n",
    "print(f\"Entrada 1,000: \\n{entradas[1_000]}\")\n",
    "print(f\"Salida 1,000: \\n{salidas[1_000]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, las salidas son iguales a las entradas pero con un adelanto, así ya podemos especificar nuestro modelo de N-gramas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo y entrenamiento\n",
    "\n",
    "El modelo es muy sencillo y podemos discutirlo mucho y modificarlo para probar nuevas cosas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
