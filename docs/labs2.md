---
title: Conceptos y modelos de aprendizaje profundo
subtitle: Laboratorios (Curso PLN/MCD/UNISON)
layout: page
hero_image: https://github.com/mcd-unison/pln/raw/main/docs/img/data-science-banner.jpg
hero_darken: true
show_sidebar: false
---

# LSTM

- [El problema del desvanecimiento del gradiente](https://www.github.com/mcd-unison/pln/blob/main/labs/RNN/vanish-grad.ipynb)

- [Una RNN a pie, solo para entender la arquitectura](https://www.github.com/mcd-unison/pln/blob/main/labs/RNN/Estados-ocultos.ipynb)

- [Análisis de sentimiento con LSTM](https://www.github.com/mcd-unison/pln/blob/main/labs/RNN/LSTM-IMdb.ipynb)

- [El problema de NER con LSTM](https://www.github.com/mcd-unison/pln/blob/main/labs/RNN/ner-lstm.ipynb)

- [Redes Siamesas para *Few-shot learning*](https://www.github.com/mcd-unison/pln/blob/main/labs/RNN/siamesas.ipynb)

# El mecanismo de atención

- [El mecanismo de atención a pie, solo para entender](https://www.github.com/mcd-unison/pln/blob/main/labs/atencion/atencion.ipynb)
  
- [Modelo *seq-to-seq* con LSTM y mecanismo de atención](https://www.tensorflow.org/text/tutorials/nmt_with_attention?hl=en)

# Atención es todo lo que necesitas

- [Un modelo 100% usando celdas tipo *self-attention*]()