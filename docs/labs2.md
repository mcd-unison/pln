---
title: Conceptos y modelos de aprendizaje profundo
subtitle: Laboratorios (Curso PLN/MCD/UNISON)
layout: page
hero_image: https://github.com/mcd-unison/pln/raw/main/docs/img/data-science-banner.jpg
hero_darken: true
show_sidebar: false
---

# LSTM

- [El problema del desvanecimiento del gradiente](https://www.github.com/mcd-unison/pln/blob/main/labs/RNN/vanish-grad.ipynb)

- [Una RNN a pie, solo para entender la arquitectura](https://www.github.com/mcd-unison/pln/blob/main/labs/RNN/Estados-ocultos.ipynb)

- [Análisis de sentimiento con LSTM](https://www.github.com/mcd-unison/pln/blob/main/labs/RNN/LSTM-IMdb.ipynb)

- [El problema de NER con LSTM](https://www.github.com/mcd-unison/pln/blob/main/labs/RNN/ner-lstm.ipynb)

- [Redes Siamesas para *Few-shot learning*](https://www.github.com/mcd-unison/pln/blob/main/labs/RNN/siamesas.ipynb)

# El mecanismo de atención

- [El mecanismo de atención a pie, solo para entender](https://www.github.com/mcd-unison/pln/blob/main/labs/atencion/atencion.ipynb)
  
- [Modelo *seq-to-seq* con LSTM y mecanismo de atención](https://www.tensorflow.org/text/tutorials/nmt_with_attention?hl=en) de los ejemplos de uso de la documentación de Tensor Flow


- [Modelo *seq-to-seq* con transformadores, haciendo los transformadores mas o menos a pie](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/nlp/ipynb/neural_machine_translation_with_transformer.ipynb) de la guías de ejemplos de la documentación de Keras


# Usando modelos preentrenados


- [A Visual Notebook to Using BERT for the First Tme](https://colab.research.google.com/github/jalammar/jalammar.github.io/blob/master/notebooks/bert/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.ipynb). libreta de [Alammar](http://jalammar.github.io) de la entrada de su blog [A Visual Guide to Using BERT for the First Time](http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/)

- [Clasificación de textos con transformers](https://colab.research.google.com/github/mcd-unison/pln/blob/main/labs/atencion/transfer-hf.ipynb). Modificación de [esta libreta que ya no funciona](https://colab.research.google.com/github/somosnlp/nlp-de-cero-a-cien/blob/main/4_transformers_aprendizaje_por_transferencia/clasificacion_de_textos.ipynb), del curso [Curso NLP de 0 a 100](https://somosnlp.org/recursos/curso-de-nlp-de-0-a-100) de la [Sesión 4: Transformers y Aprendizaje por Transferencia](https://somosnlp.org/nlp-de-cero-a-cien/sesion-04)
