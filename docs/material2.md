---
title: Conceptos y modelos de aprendizaje profundo
subtitle: Material del curso (Curso PLN/MCD/UNISON)
layout: page
hero_image: https://github.com/mcd-unison/pln/raw/main/docs/img/data-science-banner.jpg
hero_darken: true
show_sidebar: false
---

## Presentaciones usadas en el curso

- [Introducción a los modelos secuenciales y celdas LSTM]()

## Explicaciones gráficas

- [The Illustrated Transformer (Alammar, 2018)](http://jalammar.github.io/illustrated-transformer/)

- [The Illustrated GPT-2 (Visualizing Transformer Language Models) (Alammar, 2019)](http://jalammar.github.io/illustrated-gpt2/)

- [How GPT3 Works - Visualizations and Animations (Alammar, 2020)](http://jalammar.github.io/how-gpt3-works-visualizations-animations/)


## Artículos seminales

- [Attention Is All You Need (Vaswani et al, 2017)](https://arxiv.org/abs/1706.03762)

- [Deep contextualized word representations (Peters et al, 2018)](https://arxiv.org/pdf/1802.05365.pdf)

- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Devlin et al, 2018)](https://arxiv.org/abs/1810.04805)

- [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer (Raffel et al, 2019)](https://arxiv.org/abs/1910.10683)

- [Reformer: The Efficient Transformer (Kitaev et al, 2020)](https://arxiv.org/abs/2001.04451)


## Librerías

