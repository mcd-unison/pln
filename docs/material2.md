---
title: Conceptos y modelos de aprendizaje profundo
subtitle: Material del curso (Curso PLN/MCD/UNISON)
layout: page
hero_image: https://github.com/mcd-unison/pln/raw/main/docs/img/data-science-banner.jpg
hero_darken: true
show_sidebar: false
---

## Presentaciones usadas en el curso

- [Introducción a los modelos secuenciales y celdas LSTM](https://www.github.com/mcd-unison/pln/blob/main/slides/pln-capitulo-2.pptx)

- [*Name-entity Recognition* (NER) con LSTM](https://www.github.com/mcd-unison/pln/blob/main/slides/NER-LSTM.pdf)

- [Redes Siamesas y *One shoot learning*](https://www.github.com/mcd-unison/pln/blob/main/slides/NN-siamesas.pdf)


## Explicaciones gráficas

- [The Unreasonable Effectiveness of Recurrent Neural Networks (Karpathy, 2015)](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)

- [Recurrent Neural Networks cheatsheet (Amidi y Amidi, 2019)](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks)

- [The Illustrated Transformer (Alammar, 2018)](http://jalammar.github.io/illustrated-transformer/)

- [The Illustrated GPT-2 (Visualizing Transformer Language Models) (Alammar, 2019)](http://jalammar.github.io/illustrated-gpt2/)

- [How GPT3 Works - Visualizations and Animations (Alammar, 2020)](http://jalammar.github.io/how-gpt3-works-visualizations-animations/)


## Artículos seminales

- [Long Short-Term Memory (Hochreiter y Schmidhuber, 1997)](https://deeplearning.cs.cmu.edu/F23/document/readings/LSTM.pdf)

- [Understanding LSTM -- a tutorial into Long Short-Term Memory Recurrent Neural Networks (Staudemeyer y Morris, 2019)](https://arxiv.org/abs/1909.09586)

- [Attention Is All You Need (Vaswani et al, 2017)](https://arxiv.org/abs/1706.03762)

- [Deep contextualized word representations (Peters et al, 2018)](https://arxiv.org/pdf/1802.05365)

- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Devlin et al, 2018)](https://arxiv.org/abs/1810.04805)

- [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer (Raffel et al, 2019)](https://arxiv.org/abs/1910.10683)

- [Reformer: The Efficient Transformer (Kitaev et al, 2020)](https://arxiv.org/abs/2001.04451)


## Librerías

